
# üõçÔ∏è Clasificador de Productos: ¬øNuevo o Usado?

Este proyecto construye un modelo de machine learning para predecir si una publicaci√≥n en el Marketplace de Mercado Libre corresponde a un producto **nuevo** o **usado**, utilizando informaci√≥n estructurada provista por la plataforma.

---

##  Estructura del proyecto

```
project-root/
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ MLA_100k_checked_v3.jsonlines       # Dataset original
‚îÇ
‚îú‚îÄ‚îÄ output/
‚îÇ   ‚îú‚îÄ‚îÄ metricas_modelo.csv                 # M√©tricas del modelo final
‚îÇ   ‚îî‚îÄ‚îÄ X_test_with_predictions.jsonlines   # Conjunto de test con predicciones
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ eda.ipynb                           # Notebook opcional de an√°lisis exploratorio
‚îÇ   ‚îú‚îÄ‚îÄ new_or_used.py                      # Script principal ejecutable
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing.py                    # Preprocesamiento y feature engineering
‚îÇ   ‚îî‚îÄ‚îÄ utils.py                            # Funciones auxiliares (scaling, tuning, helpers)
‚îÇ
‚îî‚îÄ‚îÄ requirements.txt                        # Dependencias del proyecto
```

---

##  C√≥mo correr el proyecto

### 1. Instalar dependencias

```bash
pip install -r requirements.txt
```

### 2. Ejecutar el modelo

```bash
python src/new_or_used.py
```

Esto entrenar√° el modelo, evaluar√° su rendimiento y generar√° dos archivos en la carpeta `output/`:

- `metricas_modelo.csv`
- `X_test_with_predictions.jsonlines`


---

##  Decisiones de dise√±o

- **Target**: Se codific√≥ como `1 = new`, `0 = used`.
- **Preprocesamiento**: Se eliminan columnas con m√°s del 80% de valores nulos, con mayoria de valores string vacios o listas vacias, irrelevantes y colineales.

Se extraen features como:
  - `pictures_count`, `non_mp_methods_count`, `title_word_count`, `has_nuevo_in_title`.

Se codifican binarias utiles como:
  - `is_free_shipping`, `is_active`, `has_warranty` y `has_original_price`.
- **Encoding**: Se codifican columnas categ√≥ricas de baja cardinalidad con `LabelEncoder`. Las booleanas se convierten a `int`.
- **Selecci√≥n de variables**: Se seleccionan las features num√©ricas m√°s correlacionadas con el target (`condition_enc`).
- **Escalado**: `MinMaxScaler` aplicado s√≥lo a las features seleccionadas.
- **Modelo**: Se us√≥ `XGBoostClassifier` con hiperpar√°metros ajustados v√≠a `RandomizedSearchCV`.
- **Exportaci√≥n**: El conjunto `X_test` se guarda con columnas `predicted_condition` y `real_condition` en formato `.jsonlines`.

---

##  Resultados del modelo

| M√©trica      | Valor alcanzado |
|--------------|------------------|
| Accuracy     | ‚â• 0.88           |
| Precision    | ‚úì Calculada      |
| Recall       | ‚úì Calculada      |
| F1 Score     | ‚úì Calculada      |

> Todas las m√©tricas se pueden consultar en `output/metricas_modelo.csv`.

###  M√©tricas utilizadas

- **M√©trica principal: Accuracy**  
  En problemas de clasificaci√≥n balanceados, la **accuracy** es una m√©trica adecuada ya que representa la proporci√≥n de predicciones correctas del modelo. Fue requerida expl√≠citamente en la consigna y es f√°cilmente interpretable.

- **M√©trica secundaria: Precision**  
  Se seleccion√≥ la **precisi√≥n** como m√©trica secundaria porque nos indica **qu√© tan confiable es el modelo cuando predice que un producto es nuevo**.  
  En este contexto, **minimizar falsos positivos** es cr√≠tico: no queremos que el modelo prediga "nuevo" cuando en realidad el producto es usado, ya que eso podr√≠a generar una **mala experiencia para el cliente** y tener implicancias comerciales serias.  
  Por esta raz√≥n, se privilegia la precisi√≥n por sobre el recall como segunda m√©trica clave.

---

##  Hiperpar√°metros del modelo final

```python
XGBClassifier(
    n_estimators=900,
    max_depth=12,
    learning_rate=0.05,
    subsample=0.85,
    colsample_bytree=0.7,
    min_child_weight=1,
    gamma=0,
    scale_pos_weight=1,
    use_label_encoder=False,
    eval_metric='logloss',
    random_state=42
)
```

---

##  Dependencias clave

- `pandas`, `scikit-learn`, `xgboost`
- `matplotlib`, `seaborn` (EDA opcional)

> Todas especificadas en `requirements.txt`

---

##  An√°lisis Exploratorio (ejecucion opcional)

El archivo `eda.ipynb` explora:
- Distribuci√≥n de clases
- Calidad de los datos
- Correlaciones
- Posibles outliers o campos irrelevantes
- Experimentacion de modelos
- Seleccion de columnas optimas
- Ajuste de hiperparametros


---

## Pr√≥ximos pasos

- Incorporar NLP o LLM sobre t√≠tulo y descripci√≥n para generar nuevas features.
- Profundizar an√°lisis de columnas no tenidas en cuenta en esta primera instancia.



