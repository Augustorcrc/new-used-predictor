
# ðŸ›ï¸ Clasificador de Productos: Â¿Nuevo o Usado?

Este proyecto construye un modelo de machine learning para predecir si una publicaciÃ³n en el Marketplace de Mercado Libre corresponde a un producto **nuevo** o **usado**, utilizando informaciÃ³n estructurada provista por la plataforma.

---

## ðŸ“¦ Estructura del proyecto

```
project-root/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ MLA_100k_checked_v3.jsonlines       # Dataset original
â”‚
â”œâ”€â”€ output/
â”‚   â”œâ”€â”€ metricas_modelo.csv                 # MÃ©tricas del modelo final
â”‚   â””â”€â”€ X_test_with_predictions.jsonlines   # Conjunto de test con predicciones
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ eda.ipynb                           # Notebook opcional de anÃ¡lisis exploratorio
â”‚   â”œâ”€â”€ new_or_used.py                      # Script principal ejecutable
â”‚   â”œâ”€â”€ preprocessing.py                    # Preprocesamiento y feature engineering
â”‚   â””â”€â”€ utils.py                            # Funciones auxiliares (scaling, tuning, helpers)
â”‚
â””â”€â”€ requirements.txt                        # Dependencias del proyecto
```

---

## âš™ï¸ CÃ³mo correr el proyecto

### 1. Instalar dependencias

```bash
pip install -r requirements.txt
```

### 2. Ejecutar el modelo

```bash
python src/new_or_used.py
```

Esto entrenarÃ¡ el modelo, evaluarÃ¡ su rendimiento y generarÃ¡ dos archivos en la carpeta `output/`:

- `metricas_modelo.csv`
- `X_test_with_predictions.jsonlines`

---

## ðŸ“ˆ Resultados del modelo

| MÃ©trica      | Valor alcanzado |
|--------------|------------------|
| Accuracy     | â‰¥ 0.88           |
| Precision    | âœ“ Calculada      |
| Recall       | âœ“ Calculada      |
| F1 Score     | âœ“ Calculada      |

> Todas las mÃ©tricas se pueden consultar en `output/metricas_modelo.csv`.

### ðŸŽ¯ MÃ©tricas utilizadas

- **MÃ©trica principal: Accuracy**  
  En problemas de clasificaciÃ³n balanceados, la **accuracy** es una mÃ©trica adecuada ya que representa la proporciÃ³n de predicciones correctas del modelo. Fue requerida explÃ­citamente en la consigna y es fÃ¡cilmente interpretable.

- **MÃ©trica secundaria: Precision**  
  Se seleccionÃ³ la **precisiÃ³n** como mÃ©trica secundaria porque nos indica **quÃ© tan confiable es el modelo cuando predice que un producto es nuevo**.  
  En este contexto, **minimizar falsos positivos** es crÃ­tico: no queremos que el modelo prediga "nuevo" cuando en realidad el producto es usado, ya que eso podrÃ­a generar una **mala experiencia para el cliente** y tener implicancias comerciales serias.  
  Por esta razÃ³n, se privilegia la precisiÃ³n por sobre el recall como segunda mÃ©trica clave.

---

## ðŸ§  Decisiones de diseÃ±o

- **Target**: Se codificÃ³ como `1 = new`, `0 = used`.
- **Preprocesamiento**: Se eliminan columnas con mÃ¡s del 80% de valores nulos, mayoria de valores como string o listas vacias, irrelevantes y colineales.
Se extraen features como:
  - `pictures_count`, `non_mp_methods_count`, `title_word_count`, `has_nuevo_in_title`.
Se codifican binarias utiles como:
  - `is_free_shipping`, `is_active`, `has_warranty` y `has_original_price`.
- **Encoding**: Se codifican columnas categÃ³ricas de baja cardinalidad con `LabelEncoder`. Las booleanas se convierten a `int`.
- **SelecciÃ³n de variables**: Se seleccionan las features numÃ©ricas mÃ¡s correlacionadas con el target (`condition_enc`).
- **Escalado**: `MinMaxScaler` aplicado sÃ³lo a las features seleccionadas.
- **Modelo**: Se usÃ³ `XGBoostClassifier` con hiperparÃ¡metros ajustados vÃ­a `RandomizedSearchCV`.
- **Logging**: Se utiliza `logging` para trazabilidad del pipeline.
- **ExportaciÃ³n**: El conjunto `X_test` se guarda con columnas `predicted_condition` y `real_condition` en `.jsonlines`.

---

## ðŸ§ª HiperparÃ¡metros del modelo final

```python
XGBClassifier(
    n_estimators=900,
    max_depth=12,
    learning_rate=0.05,
    subsample=0.85,
    colsample_bytree=0.7,
    min_child_weight=1,
    gamma=0,
    scale_pos_weight=1,
    use_label_encoder=False,
    eval_metric='logloss',
    random_state=42
)
```

---

## ðŸ—‚ï¸ Dependencias clave

- `pandas`, `scikit-learn`, `xgboost`
- `matplotlib`, `seaborn` (EDA opcional)

> Todas especificadas en `requirements.txt`

---

## ðŸ“š AnÃ¡lisis Exploratorio

El archivo `eda.ipynb` explora:
- DistribuciÃ³n de clases
- Calidad de los datos
- Correlaciones
- Posibles outliers o campos irrelevantes
- Experimentacion de modelos
- Seleccion de columnas optimas
- Ajuste de hiperparametros


---


